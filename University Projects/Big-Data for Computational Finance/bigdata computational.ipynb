{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9f54469e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sales/Revenues</th>\n",
       "      <th>Gross Margin</th>\n",
       "      <th>EBITDA</th>\n",
       "      <th>EBITDA Margin</th>\n",
       "      <th>Net Income Before Extras</th>\n",
       "      <th>Total Debt</th>\n",
       "      <th>Net Debt</th>\n",
       "      <th>LT Debt</th>\n",
       "      <th>ST Debt</th>\n",
       "      <th>Cash</th>\n",
       "      <th>...</th>\n",
       "      <th>Interest Coverage</th>\n",
       "      <th>Total Liquidity</th>\n",
       "      <th>Current Liquidity</th>\n",
       "      <th>Current Liabilities</th>\n",
       "      <th>EPS Before Extras</th>\n",
       "      <th>PE</th>\n",
       "      <th>ROA</th>\n",
       "      <th>ROE</th>\n",
       "      <th>InvGrd</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.005496</td>\n",
       "      <td>0.030763</td>\n",
       "      <td>0.018885</td>\n",
       "      <td>0.024515</td>\n",
       "      <td>0.146849</td>\n",
       "      <td>-0.029710</td>\n",
       "      <td>-0.019296</td>\n",
       "      <td>-0.042648</td>\n",
       "      <td>0.049875</td>\n",
       "      <td>-0.133716</td>\n",
       "      <td>...</td>\n",
       "      <td>0.136748</td>\n",
       "      <td>0.392143</td>\n",
       "      <td>-0.184887</td>\n",
       "      <td>0.062781</td>\n",
       "      <td>0.148305</td>\n",
       "      <td>0.100409</td>\n",
       "      <td>0.163266</td>\n",
       "      <td>0.102521</td>\n",
       "      <td>1</td>\n",
       "      <td>A1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.005496</td>\n",
       "      <td>0.030763</td>\n",
       "      <td>0.088716</td>\n",
       "      <td>0.094733</td>\n",
       "      <td>0.146849</td>\n",
       "      <td>-0.029710</td>\n",
       "      <td>-0.019296</td>\n",
       "      <td>-0.042648</td>\n",
       "      <td>0.049875</td>\n",
       "      <td>-0.133716</td>\n",
       "      <td>...</td>\n",
       "      <td>0.214657</td>\n",
       "      <td>0.392143</td>\n",
       "      <td>-0.184887</td>\n",
       "      <td>0.062781</td>\n",
       "      <td>0.148305</td>\n",
       "      <td>-0.089598</td>\n",
       "      <td>0.163266</td>\n",
       "      <td>0.102521</td>\n",
       "      <td>1</td>\n",
       "      <td>A1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.007045</td>\n",
       "      <td>0.023159</td>\n",
       "      <td>0.088716</td>\n",
       "      <td>0.096440</td>\n",
       "      <td>0.108590</td>\n",
       "      <td>0.039410</td>\n",
       "      <td>0.034268</td>\n",
       "      <td>0.009059</td>\n",
       "      <td>0.250371</td>\n",
       "      <td>0.101315</td>\n",
       "      <td>...</td>\n",
       "      <td>0.205290</td>\n",
       "      <td>0.483257</td>\n",
       "      <td>-0.017877</td>\n",
       "      <td>0.121357</td>\n",
       "      <td>0.110656</td>\n",
       "      <td>-0.045142</td>\n",
       "      <td>0.105711</td>\n",
       "      <td>0.103378</td>\n",
       "      <td>1</td>\n",
       "      <td>A1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.009396</td>\n",
       "      <td>0.028400</td>\n",
       "      <td>0.088716</td>\n",
       "      <td>0.099046</td>\n",
       "      <td>0.146137</td>\n",
       "      <td>0.030071</td>\n",
       "      <td>0.036938</td>\n",
       "      <td>-0.016964</td>\n",
       "      <td>0.356994</td>\n",
       "      <td>-0.052606</td>\n",
       "      <td>...</td>\n",
       "      <td>0.232991</td>\n",
       "      <td>0.996955</td>\n",
       "      <td>-0.122017</td>\n",
       "      <td>0.079051</td>\n",
       "      <td>0.151639</td>\n",
       "      <td>-0.008231</td>\n",
       "      <td>0.162421</td>\n",
       "      <td>0.132295</td>\n",
       "      <td>1</td>\n",
       "      <td>A1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.009009</td>\n",
       "      <td>0.027714</td>\n",
       "      <td>0.088716</td>\n",
       "      <td>0.098611</td>\n",
       "      <td>0.123500</td>\n",
       "      <td>0.024224</td>\n",
       "      <td>0.034445</td>\n",
       "      <td>-0.034132</td>\n",
       "      <td>0.461894</td>\n",
       "      <td>-0.090869</td>\n",
       "      <td>...</td>\n",
       "      <td>0.172906</td>\n",
       "      <td>1.711426</td>\n",
       "      <td>-0.161561</td>\n",
       "      <td>0.084319</td>\n",
       "      <td>0.130435</td>\n",
       "      <td>0.015528</td>\n",
       "      <td>0.156427</td>\n",
       "      <td>0.225144</td>\n",
       "      <td>1</td>\n",
       "      <td>A1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1695</th>\n",
       "      <td>-0.099327</td>\n",
       "      <td>-0.010702</td>\n",
       "      <td>-0.127046</td>\n",
       "      <td>-0.030785</td>\n",
       "      <td>-4.349569</td>\n",
       "      <td>0.124830</td>\n",
       "      <td>0.146400</td>\n",
       "      <td>0.008407</td>\n",
       "      <td>0.364676</td>\n",
       "      <td>-0.028333</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.190974</td>\n",
       "      <td>0.603271</td>\n",
       "      <td>-0.150779</td>\n",
       "      <td>0.144187</td>\n",
       "      <td>-4.408257</td>\n",
       "      <td>-1.339781</td>\n",
       "      <td>-4.271318</td>\n",
       "      <td>-5.168673</td>\n",
       "      <td>0</td>\n",
       "      <td>Caa1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1696</th>\n",
       "      <td>-0.116919</td>\n",
       "      <td>-0.009799</td>\n",
       "      <td>-0.155183</td>\n",
       "      <td>-0.043333</td>\n",
       "      <td>-2.937747</td>\n",
       "      <td>0.157873</td>\n",
       "      <td>0.066243</td>\n",
       "      <td>0.084104</td>\n",
       "      <td>0.309846</td>\n",
       "      <td>0.808505</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.246259</td>\n",
       "      <td>0.007110</td>\n",
       "      <td>0.604043</td>\n",
       "      <td>0.127468</td>\n",
       "      <td>-2.977064</td>\n",
       "      <td>-1.695900</td>\n",
       "      <td>-2.868086</td>\n",
       "      <td>-3.429429</td>\n",
       "      <td>0</td>\n",
       "      <td>Caa1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1697</th>\n",
       "      <td>-0.099676</td>\n",
       "      <td>0.067595</td>\n",
       "      <td>-0.170022</td>\n",
       "      <td>-0.078134</td>\n",
       "      <td>-1.960264</td>\n",
       "      <td>0.023226</td>\n",
       "      <td>-0.201398</td>\n",
       "      <td>0.024856</td>\n",
       "      <td>0.020078</td>\n",
       "      <td>1.352542</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.266848</td>\n",
       "      <td>-0.959809</td>\n",
       "      <td>1.227363</td>\n",
       "      <td>0.056198</td>\n",
       "      <td>-1.955285</td>\n",
       "      <td>-1.919739</td>\n",
       "      <td>-1.876336</td>\n",
       "      <td>-1.940995</td>\n",
       "      <td>0</td>\n",
       "      <td>Caa1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1698</th>\n",
       "      <td>-0.088853</td>\n",
       "      <td>0.007820</td>\n",
       "      <td>-0.122645</td>\n",
       "      <td>-0.037088</td>\n",
       "      <td>-2.066509</td>\n",
       "      <td>0.067495</td>\n",
       "      <td>-0.011377</td>\n",
       "      <td>0.289219</td>\n",
       "      <td>-0.171802</td>\n",
       "      <td>0.671224</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.226685</td>\n",
       "      <td>-0.438389</td>\n",
       "      <td>0.865331</td>\n",
       "      <td>-0.104059</td>\n",
       "      <td>-2.059347</td>\n",
       "      <td>-1.462429</td>\n",
       "      <td>-2.027254</td>\n",
       "      <td>-2.059961</td>\n",
       "      <td>0</td>\n",
       "      <td>Caa1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1699</th>\n",
       "      <td>-0.084739</td>\n",
       "      <td>-0.021961</td>\n",
       "      <td>-0.159290</td>\n",
       "      <td>-0.081442</td>\n",
       "      <td>-1.953166</td>\n",
       "      <td>-0.043481</td>\n",
       "      <td>-0.285966</td>\n",
       "      <td>0.045902</td>\n",
       "      <td>-0.179549</td>\n",
       "      <td>1.987960</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.219651</td>\n",
       "      <td>-0.977050</td>\n",
       "      <td>2.167547</td>\n",
       "      <td>-0.056695</td>\n",
       "      <td>-1.948856</td>\n",
       "      <td>-1.918602</td>\n",
       "      <td>-1.952314</td>\n",
       "      <td>-1.758980</td>\n",
       "      <td>0</td>\n",
       "      <td>Caa1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1700 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Sales/Revenues  Gross Margin    EBITDA  EBITDA Margin  \\\n",
       "0          -0.005496      0.030763  0.018885       0.024515   \n",
       "1          -0.005496      0.030763  0.088716       0.094733   \n",
       "2          -0.007045      0.023159  0.088716       0.096440   \n",
       "3          -0.009396      0.028400  0.088716       0.099046   \n",
       "4          -0.009009      0.027714  0.088716       0.098611   \n",
       "...              ...           ...       ...            ...   \n",
       "1695       -0.099327     -0.010702 -0.127046      -0.030785   \n",
       "1696       -0.116919     -0.009799 -0.155183      -0.043333   \n",
       "1697       -0.099676      0.067595 -0.170022      -0.078134   \n",
       "1698       -0.088853      0.007820 -0.122645      -0.037088   \n",
       "1699       -0.084739     -0.021961 -0.159290      -0.081442   \n",
       "\n",
       "      Net Income Before Extras  Total Debt  Net Debt   LT Debt   ST Debt  \\\n",
       "0                     0.146849   -0.029710 -0.019296 -0.042648  0.049875   \n",
       "1                     0.146849   -0.029710 -0.019296 -0.042648  0.049875   \n",
       "2                     0.108590    0.039410  0.034268  0.009059  0.250371   \n",
       "3                     0.146137    0.030071  0.036938 -0.016964  0.356994   \n",
       "4                     0.123500    0.024224  0.034445 -0.034132  0.461894   \n",
       "...                        ...         ...       ...       ...       ...   \n",
       "1695                 -4.349569    0.124830  0.146400  0.008407  0.364676   \n",
       "1696                 -2.937747    0.157873  0.066243  0.084104  0.309846   \n",
       "1697                 -1.960264    0.023226 -0.201398  0.024856  0.020078   \n",
       "1698                 -2.066509    0.067495 -0.011377  0.289219 -0.171802   \n",
       "1699                 -1.953166   -0.043481 -0.285966  0.045902 -0.179549   \n",
       "\n",
       "          Cash  ...  Interest Coverage  Total Liquidity  Current Liquidity  \\\n",
       "0    -0.133716  ...           0.136748         0.392143          -0.184887   \n",
       "1    -0.133716  ...           0.214657         0.392143          -0.184887   \n",
       "2     0.101315  ...           0.205290         0.483257          -0.017877   \n",
       "3    -0.052606  ...           0.232991         0.996955          -0.122017   \n",
       "4    -0.090869  ...           0.172906         1.711426          -0.161561   \n",
       "...        ...  ...                ...              ...                ...   \n",
       "1695 -0.028333  ...          -0.190974         0.603271          -0.150779   \n",
       "1696  0.808505  ...          -0.246259         0.007110           0.604043   \n",
       "1697  1.352542  ...          -0.266848        -0.959809           1.227363   \n",
       "1698  0.671224  ...          -0.226685        -0.438389           0.865331   \n",
       "1699  1.987960  ...          -0.219651        -0.977050           2.167547   \n",
       "\n",
       "      Current Liabilities  EPS Before Extras        PE       ROA       ROE  \\\n",
       "0                0.062781           0.148305  0.100409  0.163266  0.102521   \n",
       "1                0.062781           0.148305 -0.089598  0.163266  0.102521   \n",
       "2                0.121357           0.110656 -0.045142  0.105711  0.103378   \n",
       "3                0.079051           0.151639 -0.008231  0.162421  0.132295   \n",
       "4                0.084319           0.130435  0.015528  0.156427  0.225144   \n",
       "...                   ...                ...       ...       ...       ...   \n",
       "1695             0.144187          -4.408257 -1.339781 -4.271318 -5.168673   \n",
       "1696             0.127468          -2.977064 -1.695900 -2.868086 -3.429429   \n",
       "1697             0.056198          -1.955285 -1.919739 -1.876336 -1.940995   \n",
       "1698            -0.104059          -2.059347 -1.462429 -2.027254 -2.059961   \n",
       "1699            -0.056695          -1.948856 -1.918602 -1.952314 -1.758980   \n",
       "\n",
       "      InvGrd  Rating  \n",
       "0          1      A1  \n",
       "1          1      A1  \n",
       "2          1      A1  \n",
       "3          1      A1  \n",
       "4          1      A1  \n",
       "...      ...     ...  \n",
       "1695       0    Caa1  \n",
       "1696       0    Caa1  \n",
       "1697       0    Caa1  \n",
       "1698       0    Caa1  \n",
       "1699       0    Caa1  \n",
       "\n",
       "[1700 rows x 28 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as mt\n",
    "crds=pd.read_csv(r\"C:\\Users\\DELL\\Downloads\\MLF_GP1_CreditScore.csv\")\n",
    "crds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "14733aa4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1700, 28)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crds.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b00d613e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sales/Revenues</th>\n",
       "      <th>Gross Margin</th>\n",
       "      <th>EBITDA</th>\n",
       "      <th>EBITDA Margin</th>\n",
       "      <th>Net Income Before Extras</th>\n",
       "      <th>Total Debt</th>\n",
       "      <th>Net Debt</th>\n",
       "      <th>LT Debt</th>\n",
       "      <th>ST Debt</th>\n",
       "      <th>Cash</th>\n",
       "      <th>...</th>\n",
       "      <th>CFO</th>\n",
       "      <th>Interest Coverage</th>\n",
       "      <th>Total Liquidity</th>\n",
       "      <th>Current Liquidity</th>\n",
       "      <th>Current Liabilities</th>\n",
       "      <th>EPS Before Extras</th>\n",
       "      <th>PE</th>\n",
       "      <th>ROA</th>\n",
       "      <th>ROE</th>\n",
       "      <th>InvGrd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1700.000000</td>\n",
       "      <td>1700.000000</td>\n",
       "      <td>1700.000000</td>\n",
       "      <td>1700.000000</td>\n",
       "      <td>1700.000000</td>\n",
       "      <td>1700.000000</td>\n",
       "      <td>1700.000000</td>\n",
       "      <td>1700.000000</td>\n",
       "      <td>1700.000000</td>\n",
       "      <td>1700.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1700.000000</td>\n",
       "      <td>1700.000000</td>\n",
       "      <td>1700.000000</td>\n",
       "      <td>1700.000000</td>\n",
       "      <td>1700.000000</td>\n",
       "      <td>1700.000000</td>\n",
       "      <td>1700.000000</td>\n",
       "      <td>1700.000000</td>\n",
       "      <td>1700.000000</td>\n",
       "      <td>1700.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.050378</td>\n",
       "      <td>0.026007</td>\n",
       "      <td>0.068718</td>\n",
       "      <td>0.021074</td>\n",
       "      <td>0.123026</td>\n",
       "      <td>0.822405</td>\n",
       "      <td>-0.419810</td>\n",
       "      <td>1.255168</td>\n",
       "      <td>3.142797</td>\n",
       "      <td>0.466620</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.189317</td>\n",
       "      <td>0.298785</td>\n",
       "      <td>-0.855714</td>\n",
       "      <td>0.436002</td>\n",
       "      <td>0.072802</td>\n",
       "      <td>0.032196</td>\n",
       "      <td>0.497705</td>\n",
       "      <td>0.019394</td>\n",
       "      <td>-0.217604</td>\n",
       "      <td>0.757059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.161910</td>\n",
       "      <td>0.273768</td>\n",
       "      <td>0.237365</td>\n",
       "      <td>0.189025</td>\n",
       "      <td>14.475689</td>\n",
       "      <td>13.317075</td>\n",
       "      <td>28.385702</td>\n",
       "      <td>16.224453</td>\n",
       "      <td>51.986550</td>\n",
       "      <td>1.859494</td>\n",
       "      <td>...</td>\n",
       "      <td>5.668669</td>\n",
       "      <td>5.265291</td>\n",
       "      <td>22.926862</td>\n",
       "      <td>1.904282</td>\n",
       "      <td>0.266471</td>\n",
       "      <td>6.151994</td>\n",
       "      <td>12.102502</td>\n",
       "      <td>14.594193</td>\n",
       "      <td>15.389000</td>\n",
       "      <td>0.428986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-0.661715</td>\n",
       "      <td>-0.794722</td>\n",
       "      <td>-0.782254</td>\n",
       "      <td>-0.805153</td>\n",
       "      <td>-289.000000</td>\n",
       "      <td>-0.903014</td>\n",
       "      <td>-493.305578</td>\n",
       "      <td>-0.921515</td>\n",
       "      <td>-0.997692</td>\n",
       "      <td>-0.990982</td>\n",
       "      <td>...</td>\n",
       "      <td>-161.609425</td>\n",
       "      <td>-0.991976</td>\n",
       "      <td>-502.000000</td>\n",
       "      <td>-0.994141</td>\n",
       "      <td>-0.684678</td>\n",
       "      <td>-96.250000</td>\n",
       "      <td>-59.795133</td>\n",
       "      <td>-305.462167</td>\n",
       "      <td>-373.837267</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-0.005693</td>\n",
       "      <td>-0.020028</td>\n",
       "      <td>-0.022640</td>\n",
       "      <td>-0.042771</td>\n",
       "      <td>-0.158478</td>\n",
       "      <td>-0.076316</td>\n",
       "      <td>-0.120725</td>\n",
       "      <td>-0.094767</td>\n",
       "      <td>-0.337959</td>\n",
       "      <td>-0.195117</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.115159</td>\n",
       "      <td>-0.096996</td>\n",
       "      <td>-0.857013</td>\n",
       "      <td>-0.227327</td>\n",
       "      <td>-0.072734</td>\n",
       "      <td>-0.152894</td>\n",
       "      <td>-0.293521</td>\n",
       "      <td>-0.208483</td>\n",
       "      <td>-0.233955</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.034000</td>\n",
       "      <td>0.003403</td>\n",
       "      <td>0.049482</td>\n",
       "      <td>0.011134</td>\n",
       "      <td>0.056627</td>\n",
       "      <td>0.005886</td>\n",
       "      <td>-0.003060</td>\n",
       "      <td>-0.002078</td>\n",
       "      <td>0.043092</td>\n",
       "      <td>0.075820</td>\n",
       "      <td>...</td>\n",
       "      <td>0.046983</td>\n",
       "      <td>0.043216</td>\n",
       "      <td>-0.229098</td>\n",
       "      <td>0.040446</td>\n",
       "      <td>0.041785</td>\n",
       "      <td>0.066027</td>\n",
       "      <td>-0.040405</td>\n",
       "      <td>-0.009403</td>\n",
       "      <td>-0.020392</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.083004</td>\n",
       "      <td>0.025595</td>\n",
       "      <td>0.124533</td>\n",
       "      <td>0.060566</td>\n",
       "      <td>0.222219</td>\n",
       "      <td>0.136449</td>\n",
       "      <td>0.160251</td>\n",
       "      <td>0.174735</td>\n",
       "      <td>0.649475</td>\n",
       "      <td>0.483113</td>\n",
       "      <td>...</td>\n",
       "      <td>0.216432</td>\n",
       "      <td>0.177340</td>\n",
       "      <td>0.512778</td>\n",
       "      <td>0.416067</td>\n",
       "      <td>0.161215</td>\n",
       "      <td>0.236046</td>\n",
       "      <td>0.168897</td>\n",
       "      <td>0.156136</td>\n",
       "      <td>0.201596</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2.277229</td>\n",
       "      <td>3.202713</td>\n",
       "      <td>3.542425</td>\n",
       "      <td>4.141182</td>\n",
       "      <td>478.280075</td>\n",
       "      <td>281.604237</td>\n",
       "      <td>865.194595</td>\n",
       "      <td>289.388178</td>\n",
       "      <td>2038.000000</td>\n",
       "      <td>36.980037</td>\n",
       "      <td>...</td>\n",
       "      <td>13.005788</td>\n",
       "      <td>182.131887</td>\n",
       "      <td>280.138728</td>\n",
       "      <td>34.372455</td>\n",
       "      <td>4.194381</td>\n",
       "      <td>187.000000</td>\n",
       "      <td>381.243282</td>\n",
       "      <td>474.847172</td>\n",
       "      <td>343.145356</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Sales/Revenues  Gross Margin       EBITDA  EBITDA Margin  \\\n",
       "count     1700.000000   1700.000000  1700.000000    1700.000000   \n",
       "mean         0.050378      0.026007     0.068718       0.021074   \n",
       "std          0.161910      0.273768     0.237365       0.189025   \n",
       "min         -0.661715     -0.794722    -0.782254      -0.805153   \n",
       "25%         -0.005693     -0.020028    -0.022640      -0.042771   \n",
       "50%          0.034000      0.003403     0.049482       0.011134   \n",
       "75%          0.083004      0.025595     0.124533       0.060566   \n",
       "max          2.277229      3.202713     3.542425       4.141182   \n",
       "\n",
       "       Net Income Before Extras   Total Debt     Net Debt      LT Debt  \\\n",
       "count               1700.000000  1700.000000  1700.000000  1700.000000   \n",
       "mean                   0.123026     0.822405    -0.419810     1.255168   \n",
       "std                   14.475689    13.317075    28.385702    16.224453   \n",
       "min                 -289.000000    -0.903014  -493.305578    -0.921515   \n",
       "25%                   -0.158478    -0.076316    -0.120725    -0.094767   \n",
       "50%                    0.056627     0.005886    -0.003060    -0.002078   \n",
       "75%                    0.222219     0.136449     0.160251     0.174735   \n",
       "max                  478.280075   281.604237   865.194595   289.388178   \n",
       "\n",
       "           ST Debt         Cash  ...          CFO  Interest Coverage  \\\n",
       "count  1700.000000  1700.000000  ...  1700.000000        1700.000000   \n",
       "mean      3.142797     0.466620  ...    -0.189317           0.298785   \n",
       "std      51.986550     1.859494  ...     5.668669           5.265291   \n",
       "min      -0.997692    -0.990982  ...  -161.609425          -0.991976   \n",
       "25%      -0.337959    -0.195117  ...    -0.115159          -0.096996   \n",
       "50%       0.043092     0.075820  ...     0.046983           0.043216   \n",
       "75%       0.649475     0.483113  ...     0.216432           0.177340   \n",
       "max    2038.000000    36.980037  ...    13.005788         182.131887   \n",
       "\n",
       "       Total Liquidity  Current Liquidity  Current Liabilities  \\\n",
       "count      1700.000000        1700.000000          1700.000000   \n",
       "mean         -0.855714           0.436002             0.072802   \n",
       "std          22.926862           1.904282             0.266471   \n",
       "min        -502.000000          -0.994141            -0.684678   \n",
       "25%          -0.857013          -0.227327            -0.072734   \n",
       "50%          -0.229098           0.040446             0.041785   \n",
       "75%           0.512778           0.416067             0.161215   \n",
       "max         280.138728          34.372455             4.194381   \n",
       "\n",
       "       EPS Before Extras           PE          ROA          ROE       InvGrd  \n",
       "count        1700.000000  1700.000000  1700.000000  1700.000000  1700.000000  \n",
       "mean            0.032196     0.497705     0.019394    -0.217604     0.757059  \n",
       "std             6.151994    12.102502    14.594193    15.389000     0.428986  \n",
       "min           -96.250000   -59.795133  -305.462167  -373.837267     0.000000  \n",
       "25%            -0.152894    -0.293521    -0.208483    -0.233955     1.000000  \n",
       "50%             0.066027    -0.040405    -0.009403    -0.020392     1.000000  \n",
       "75%             0.236046     0.168897     0.156136     0.201596     1.000000  \n",
       "max           187.000000   381.243282   474.847172   343.145356     1.000000  \n",
       "\n",
       "[8 rows x 27 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crds.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "8ca608f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sales/Revenues              0\n",
       "Gross Margin                0\n",
       "EBITDA                      0\n",
       "EBITDA Margin               0\n",
       "Net Income Before Extras    0\n",
       "Total Debt                  0\n",
       "Net Debt                    0\n",
       "LT Debt                     0\n",
       "ST Debt                     0\n",
       "Cash                        0\n",
       "Free Cash Flow              0\n",
       "Total Debt/EBITDA           0\n",
       "Net Debt/EBITDA             0\n",
       "Total MV                    0\n",
       "Total Debt/MV               0\n",
       "Net Debt/MV                 0\n",
       "CFO/Debt                    0\n",
       "CFO                         0\n",
       "Interest Coverage           0\n",
       "Total Liquidity             0\n",
       "Current Liquidity           0\n",
       "Current Liabilities         0\n",
       "EPS Before Extras           0\n",
       "PE                          0\n",
       "ROA                         0\n",
       "ROE                         0\n",
       "InvGrd                      0\n",
       "Rating                      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crds.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "126eeac1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1700 entries, 0 to 1699\n",
      "Data columns (total 28 columns):\n",
      " #   Column                    Non-Null Count  Dtype  \n",
      "---  ------                    --------------  -----  \n",
      " 0   Sales/Revenues            1700 non-null   float64\n",
      " 1   Gross Margin              1700 non-null   float64\n",
      " 2   EBITDA                    1700 non-null   float64\n",
      " 3   EBITDA Margin             1700 non-null   float64\n",
      " 4   Net Income Before Extras  1700 non-null   float64\n",
      " 5   Total Debt                1700 non-null   float64\n",
      " 6   Net Debt                  1700 non-null   float64\n",
      " 7   LT Debt                   1700 non-null   float64\n",
      " 8   ST Debt                   1700 non-null   float64\n",
      " 9   Cash                      1700 non-null   float64\n",
      " 10  Free Cash Flow            1700 non-null   float64\n",
      " 11  Total Debt/EBITDA         1700 non-null   float64\n",
      " 12  Net Debt/EBITDA           1700 non-null   float64\n",
      " 13  Total MV                  1700 non-null   float64\n",
      " 14  Total Debt/MV             1700 non-null   float64\n",
      " 15  Net Debt/MV               1700 non-null   float64\n",
      " 16  CFO/Debt                  1700 non-null   float64\n",
      " 17  CFO                       1700 non-null   float64\n",
      " 18  Interest Coverage         1700 non-null   float64\n",
      " 19  Total Liquidity           1700 non-null   float64\n",
      " 20  Current Liquidity         1700 non-null   float64\n",
      " 21  Current Liabilities       1700 non-null   float64\n",
      " 22  EPS Before Extras         1700 non-null   float64\n",
      " 23  PE                        1700 non-null   float64\n",
      " 24  ROA                       1700 non-null   float64\n",
      " 25  ROE                       1700 non-null   float64\n",
      " 26  InvGrd                    1700 non-null   int64  \n",
      " 27  Rating                    1700 non-null   object \n",
      "dtypes: float64(26), int64(1), object(1)\n",
      "memory usage: 372.0+ KB\n"
     ]
    }
   ],
   "source": [
    "crds.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a5375148",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sales/Revenues</th>\n",
       "      <th>Gross Margin</th>\n",
       "      <th>EBITDA</th>\n",
       "      <th>EBITDA Margin</th>\n",
       "      <th>Net Income Before Extras</th>\n",
       "      <th>Total Debt</th>\n",
       "      <th>Net Debt</th>\n",
       "      <th>LT Debt</th>\n",
       "      <th>ST Debt</th>\n",
       "      <th>Cash</th>\n",
       "      <th>...</th>\n",
       "      <th>CFO</th>\n",
       "      <th>Interest Coverage</th>\n",
       "      <th>Total Liquidity</th>\n",
       "      <th>Current Liquidity</th>\n",
       "      <th>Current Liabilities</th>\n",
       "      <th>EPS Before Extras</th>\n",
       "      <th>PE</th>\n",
       "      <th>ROA</th>\n",
       "      <th>ROE</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.005496</td>\n",
       "      <td>0.030763</td>\n",
       "      <td>0.018885</td>\n",
       "      <td>0.024515</td>\n",
       "      <td>0.146849</td>\n",
       "      <td>-0.029710</td>\n",
       "      <td>-0.019296</td>\n",
       "      <td>-0.042648</td>\n",
       "      <td>0.049875</td>\n",
       "      <td>-0.133716</td>\n",
       "      <td>...</td>\n",
       "      <td>0.068526</td>\n",
       "      <td>0.136748</td>\n",
       "      <td>0.392143</td>\n",
       "      <td>-0.184887</td>\n",
       "      <td>0.062781</td>\n",
       "      <td>0.148305</td>\n",
       "      <td>0.100409</td>\n",
       "      <td>0.163266</td>\n",
       "      <td>0.102521</td>\n",
       "      <td>A1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.005496</td>\n",
       "      <td>0.030763</td>\n",
       "      <td>0.088716</td>\n",
       "      <td>0.094733</td>\n",
       "      <td>0.146849</td>\n",
       "      <td>-0.029710</td>\n",
       "      <td>-0.019296</td>\n",
       "      <td>-0.042648</td>\n",
       "      <td>0.049875</td>\n",
       "      <td>-0.133716</td>\n",
       "      <td>...</td>\n",
       "      <td>0.068526</td>\n",
       "      <td>0.214657</td>\n",
       "      <td>0.392143</td>\n",
       "      <td>-0.184887</td>\n",
       "      <td>0.062781</td>\n",
       "      <td>0.148305</td>\n",
       "      <td>-0.089598</td>\n",
       "      <td>0.163266</td>\n",
       "      <td>0.102521</td>\n",
       "      <td>A1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.007045</td>\n",
       "      <td>0.023159</td>\n",
       "      <td>0.088716</td>\n",
       "      <td>0.096440</td>\n",
       "      <td>0.108590</td>\n",
       "      <td>0.039410</td>\n",
       "      <td>0.034268</td>\n",
       "      <td>0.009059</td>\n",
       "      <td>0.250371</td>\n",
       "      <td>0.101315</td>\n",
       "      <td>...</td>\n",
       "      <td>0.068136</td>\n",
       "      <td>0.205290</td>\n",
       "      <td>0.483257</td>\n",
       "      <td>-0.017877</td>\n",
       "      <td>0.121357</td>\n",
       "      <td>0.110656</td>\n",
       "      <td>-0.045142</td>\n",
       "      <td>0.105711</td>\n",
       "      <td>0.103378</td>\n",
       "      <td>A1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.009396</td>\n",
       "      <td>0.028400</td>\n",
       "      <td>0.088716</td>\n",
       "      <td>0.099046</td>\n",
       "      <td>0.146137</td>\n",
       "      <td>0.030071</td>\n",
       "      <td>0.036938</td>\n",
       "      <td>-0.016964</td>\n",
       "      <td>0.356994</td>\n",
       "      <td>-0.052606</td>\n",
       "      <td>...</td>\n",
       "      <td>0.073784</td>\n",
       "      <td>0.232991</td>\n",
       "      <td>0.996955</td>\n",
       "      <td>-0.122017</td>\n",
       "      <td>0.079051</td>\n",
       "      <td>0.151639</td>\n",
       "      <td>-0.008231</td>\n",
       "      <td>0.162421</td>\n",
       "      <td>0.132295</td>\n",
       "      <td>A1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.009009</td>\n",
       "      <td>0.027714</td>\n",
       "      <td>0.088716</td>\n",
       "      <td>0.098611</td>\n",
       "      <td>0.123500</td>\n",
       "      <td>0.024224</td>\n",
       "      <td>0.034445</td>\n",
       "      <td>-0.034132</td>\n",
       "      <td>0.461894</td>\n",
       "      <td>-0.090869</td>\n",
       "      <td>...</td>\n",
       "      <td>0.132845</td>\n",
       "      <td>0.172906</td>\n",
       "      <td>1.711426</td>\n",
       "      <td>-0.161561</td>\n",
       "      <td>0.084319</td>\n",
       "      <td>0.130435</td>\n",
       "      <td>0.015528</td>\n",
       "      <td>0.156427</td>\n",
       "      <td>0.225144</td>\n",
       "      <td>A1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1695</th>\n",
       "      <td>-0.099327</td>\n",
       "      <td>-0.010702</td>\n",
       "      <td>-0.127046</td>\n",
       "      <td>-0.030785</td>\n",
       "      <td>-4.349569</td>\n",
       "      <td>0.124830</td>\n",
       "      <td>0.146400</td>\n",
       "      <td>0.008407</td>\n",
       "      <td>0.364676</td>\n",
       "      <td>-0.028333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.516587</td>\n",
       "      <td>-0.190974</td>\n",
       "      <td>0.603271</td>\n",
       "      <td>-0.150779</td>\n",
       "      <td>0.144187</td>\n",
       "      <td>-4.408257</td>\n",
       "      <td>-1.339781</td>\n",
       "      <td>-4.271318</td>\n",
       "      <td>-5.168673</td>\n",
       "      <td>Caa1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1696</th>\n",
       "      <td>-0.116919</td>\n",
       "      <td>-0.009799</td>\n",
       "      <td>-0.155183</td>\n",
       "      <td>-0.043333</td>\n",
       "      <td>-2.937747</td>\n",
       "      <td>0.157873</td>\n",
       "      <td>0.066243</td>\n",
       "      <td>0.084104</td>\n",
       "      <td>0.309846</td>\n",
       "      <td>0.808505</td>\n",
       "      <td>...</td>\n",
       "      <td>1.840865</td>\n",
       "      <td>-0.246259</td>\n",
       "      <td>0.007110</td>\n",
       "      <td>0.604043</td>\n",
       "      <td>0.127468</td>\n",
       "      <td>-2.977064</td>\n",
       "      <td>-1.695900</td>\n",
       "      <td>-2.868086</td>\n",
       "      <td>-3.429429</td>\n",
       "      <td>Caa1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1697</th>\n",
       "      <td>-0.099676</td>\n",
       "      <td>0.067595</td>\n",
       "      <td>-0.170022</td>\n",
       "      <td>-0.078134</td>\n",
       "      <td>-1.960264</td>\n",
       "      <td>0.023226</td>\n",
       "      <td>-0.201398</td>\n",
       "      <td>0.024856</td>\n",
       "      <td>0.020078</td>\n",
       "      <td>1.352542</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.826901</td>\n",
       "      <td>-0.266848</td>\n",
       "      <td>-0.959809</td>\n",
       "      <td>1.227363</td>\n",
       "      <td>0.056198</td>\n",
       "      <td>-1.955285</td>\n",
       "      <td>-1.919739</td>\n",
       "      <td>-1.876336</td>\n",
       "      <td>-1.940995</td>\n",
       "      <td>Caa1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1698</th>\n",
       "      <td>-0.088853</td>\n",
       "      <td>0.007820</td>\n",
       "      <td>-0.122645</td>\n",
       "      <td>-0.037088</td>\n",
       "      <td>-2.066509</td>\n",
       "      <td>0.067495</td>\n",
       "      <td>-0.011377</td>\n",
       "      <td>0.289219</td>\n",
       "      <td>-0.171802</td>\n",
       "      <td>0.671224</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.556247</td>\n",
       "      <td>-0.226685</td>\n",
       "      <td>-0.438389</td>\n",
       "      <td>0.865331</td>\n",
       "      <td>-0.104059</td>\n",
       "      <td>-2.059347</td>\n",
       "      <td>-1.462429</td>\n",
       "      <td>-2.027254</td>\n",
       "      <td>-2.059961</td>\n",
       "      <td>Caa1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1699</th>\n",
       "      <td>-0.084739</td>\n",
       "      <td>-0.021961</td>\n",
       "      <td>-0.159290</td>\n",
       "      <td>-0.081442</td>\n",
       "      <td>-1.953166</td>\n",
       "      <td>-0.043481</td>\n",
       "      <td>-0.285966</td>\n",
       "      <td>0.045902</td>\n",
       "      <td>-0.179549</td>\n",
       "      <td>1.987960</td>\n",
       "      <td>...</td>\n",
       "      <td>1.789100</td>\n",
       "      <td>-0.219651</td>\n",
       "      <td>-0.977050</td>\n",
       "      <td>2.167547</td>\n",
       "      <td>-0.056695</td>\n",
       "      <td>-1.948856</td>\n",
       "      <td>-1.918602</td>\n",
       "      <td>-1.952314</td>\n",
       "      <td>-1.758980</td>\n",
       "      <td>Caa1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1700 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Sales/Revenues  Gross Margin    EBITDA  EBITDA Margin  \\\n",
       "0          -0.005496      0.030763  0.018885       0.024515   \n",
       "1          -0.005496      0.030763  0.088716       0.094733   \n",
       "2          -0.007045      0.023159  0.088716       0.096440   \n",
       "3          -0.009396      0.028400  0.088716       0.099046   \n",
       "4          -0.009009      0.027714  0.088716       0.098611   \n",
       "...              ...           ...       ...            ...   \n",
       "1695       -0.099327     -0.010702 -0.127046      -0.030785   \n",
       "1696       -0.116919     -0.009799 -0.155183      -0.043333   \n",
       "1697       -0.099676      0.067595 -0.170022      -0.078134   \n",
       "1698       -0.088853      0.007820 -0.122645      -0.037088   \n",
       "1699       -0.084739     -0.021961 -0.159290      -0.081442   \n",
       "\n",
       "      Net Income Before Extras  Total Debt  Net Debt   LT Debt   ST Debt  \\\n",
       "0                     0.146849   -0.029710 -0.019296 -0.042648  0.049875   \n",
       "1                     0.146849   -0.029710 -0.019296 -0.042648  0.049875   \n",
       "2                     0.108590    0.039410  0.034268  0.009059  0.250371   \n",
       "3                     0.146137    0.030071  0.036938 -0.016964  0.356994   \n",
       "4                     0.123500    0.024224  0.034445 -0.034132  0.461894   \n",
       "...                        ...         ...       ...       ...       ...   \n",
       "1695                 -4.349569    0.124830  0.146400  0.008407  0.364676   \n",
       "1696                 -2.937747    0.157873  0.066243  0.084104  0.309846   \n",
       "1697                 -1.960264    0.023226 -0.201398  0.024856  0.020078   \n",
       "1698                 -2.066509    0.067495 -0.011377  0.289219 -0.171802   \n",
       "1699                 -1.953166   -0.043481 -0.285966  0.045902 -0.179549   \n",
       "\n",
       "          Cash  ...       CFO  Interest Coverage  Total Liquidity  \\\n",
       "0    -0.133716  ...  0.068526           0.136748         0.392143   \n",
       "1    -0.133716  ...  0.068526           0.214657         0.392143   \n",
       "2     0.101315  ...  0.068136           0.205290         0.483257   \n",
       "3    -0.052606  ...  0.073784           0.232991         0.996955   \n",
       "4    -0.090869  ...  0.132845           0.172906         1.711426   \n",
       "...        ...  ...       ...                ...              ...   \n",
       "1695 -0.028333  ...  0.516587          -0.190974         0.603271   \n",
       "1696  0.808505  ...  1.840865          -0.246259         0.007110   \n",
       "1697  1.352542  ... -2.826901          -0.266848        -0.959809   \n",
       "1698  0.671224  ... -0.556247          -0.226685        -0.438389   \n",
       "1699  1.987960  ...  1.789100          -0.219651        -0.977050   \n",
       "\n",
       "      Current Liquidity  Current Liabilities  EPS Before Extras        PE  \\\n",
       "0             -0.184887             0.062781           0.148305  0.100409   \n",
       "1             -0.184887             0.062781           0.148305 -0.089598   \n",
       "2             -0.017877             0.121357           0.110656 -0.045142   \n",
       "3             -0.122017             0.079051           0.151639 -0.008231   \n",
       "4             -0.161561             0.084319           0.130435  0.015528   \n",
       "...                 ...                  ...                ...       ...   \n",
       "1695          -0.150779             0.144187          -4.408257 -1.339781   \n",
       "1696           0.604043             0.127468          -2.977064 -1.695900   \n",
       "1697           1.227363             0.056198          -1.955285 -1.919739   \n",
       "1698           0.865331            -0.104059          -2.059347 -1.462429   \n",
       "1699           2.167547            -0.056695          -1.948856 -1.918602   \n",
       "\n",
       "           ROA       ROE  Rating  \n",
       "0     0.163266  0.102521      A1  \n",
       "1     0.163266  0.102521      A1  \n",
       "2     0.105711  0.103378      A1  \n",
       "3     0.162421  0.132295      A1  \n",
       "4     0.156427  0.225144      A1  \n",
       "...        ...       ...     ...  \n",
       "1695 -4.271318 -5.168673    Caa1  \n",
       "1696 -2.868086 -3.429429    Caa1  \n",
       "1697 -1.876336 -1.940995    Caa1  \n",
       "1698 -2.027254 -2.059961    Caa1  \n",
       "1699 -1.952314 -1.758980    Caa1  \n",
       "\n",
       "[1700 rows x 27 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yy=crds['InvGrd']\n",
    "xx=crds.drop(['InvGrd'],axis=1)\n",
    "xx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "7d986553",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "lble=LabelEncoder()\n",
    "xx['Rating']=lble.fit_transform(xx['Rating'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "b669fec1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.bar(crds[\"Rating\"],crds['InvGrd'])\n",
    "plt.xlabel('rating')\n",
    "plt.ylabel('investment_grade')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "7a4ad800",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1492    1\n",
       "115     1\n",
       "135     1\n",
       "352     1\n",
       "1302    1\n",
       "       ..\n",
       "1231    1\n",
       "864     0\n",
       "1173    1\n",
       "1589    1\n",
       "916     0\n",
       "Name: InvGrd, Length: 340, dtype: int64"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "xx_train,xx_test,yy_train,yy_test=train_test_split(xx,yy,test_size=0.20,random_state=42)\n",
    "xx_train\n",
    "xx_test\n",
    "yy_train\n",
    "yy_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "385546bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 3.52057498e-01,  8.60917820e-03,  3.55168546e-01, ...,\n",
       "        -3.67310957e-03,  8.39379060e-03,  8.80989247e-01],\n",
       "       [ 1.26311131e-01, -1.70415320e-01, -1.40072281e-01, ...,\n",
       "         6.01218820e-04,  1.06273887e-02,  8.80989247e-01],\n",
       "       [-1.77729233e-02, -1.75028218e-02, -4.92705671e-01, ...,\n",
       "        -4.75837768e-02, -2.82405847e-02,  8.80989247e-01],\n",
       "       ...,\n",
       "       [-3.11932499e-01, -2.42070508e-01, -7.34645462e-01, ...,\n",
       "        -5.19534147e-03,  1.23091729e-02,  4.78994489e-01],\n",
       "       [-2.18126878e+00,  7.53952356e-01, -7.08856482e-01, ...,\n",
       "         3.72409613e-03,  1.70926283e-02,  1.08198663e+00],\n",
       "       [-2.03649959e-01,  2.14737002e-02, -2.41789287e-02, ...,\n",
       "        -1.83765991e-03,  2.45638704e-02,  6.79991868e-01]])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scal_r=StandardScaler()\n",
    "scal_r.fit(xx_train)\n",
    "xx_train=scal_r.transform(xx_train)\n",
    "xx_test=scal_r.transform(xx_test)\n",
    "xx_test\n",
    "xx_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "48f83c8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.75613476,  0.82048216,  0.79964214,  0.82091657,  0.83243689,\n",
       "        0.68131741,  0.67956561,  0.87685699,  0.74155026,  0.75579328,\n",
       "        0.65404305,  0.73780597,  0.79714412,  0.74466629,  0.7925219 ,\n",
       "        0.80515765,  0.81997589,  0.70557341,  0.7437413 ,  0.72004082,\n",
       "        0.78080746,  0.72454274,  0.84350464,  0.80768141,  0.69233603,\n",
       "        0.70832973,  1.02367807,  0.79973575,  0.70883817,  0.75872438,\n",
       "        0.78457261,  0.8483161 ,  0.78805998,  0.75699443,  0.8122975 ,\n",
       "        0.52539877,  0.80429868,  0.74745156,  0.74025974,  0.74787087,\n",
       "        0.80373184,  0.74403345,  0.75097921,  0.73497567,  0.78928972,\n",
       "       -0.05676438,  0.72575494,  0.76698779,  0.81259199,  0.81106116,\n",
       "        0.83248741,  0.70959901,  0.84423027,  0.8086341 ,  0.74055951,\n",
       "        0.75565198,  0.75876847,  0.81615071,  0.63897284,  0.7610646 ,\n",
       "        0.76712848,  0.73024353,  0.82458012,  0.79579688,  0.76753647,\n",
       "        0.79506695,  0.80077899,  0.8035292 ,  0.63982408,  0.77392194,\n",
       "        0.75372923,  0.78748855,  0.74489405,  0.80592546,  0.74907867,\n",
       "        0.72032782,  0.80603555,  0.74257223,  0.85486288,  0.81300581,\n",
       "        0.62499881,  0.83885157,  0.73748491,  0.77540847,  0.73641396,\n",
       "        0.7342595 ,  0.85325175,  0.83385764,  0.80384045,  0.83562837,\n",
       "        0.73157356,  0.80262047,  0.66301252,  0.81567817,  0.72481251,\n",
       "        0.83737166,  0.75911482,  0.74794452,  0.76755235,  0.81820529,\n",
       "        0.77434927,  0.70898878,  0.78841377,  0.8078902 ,  0.87900646,\n",
       "        0.80213196,  0.79506741,  0.70838181,  0.81994825,  0.6285098 ,\n",
       "        0.9079362 ,  0.74432291,  0.88130989,  0.73451058,  0.77737911,\n",
       "        0.71862249,  0.81381255,  0.77729978,  0.81771664,  0.73840962,\n",
       "        1.26782989,  0.7083009 ,  0.81494657,  0.79911179,  0.67587012,\n",
       "        0.80500899,  0.83721043,  0.84751436,  0.74012715,  0.62646698,\n",
       "        0.70206899,  0.76465759,  0.76070592,  0.27895574,  0.78018736,\n",
       "        0.81050688,  0.75842551,  0.73916841,  0.78060583,  0.82726533,\n",
       "        0.77725462,  0.84672632,  0.79462209,  0.48103931,  0.78158151,\n",
       "        0.71639298,  0.78348146,  0.81331341,  0.74645779,  0.83252767,\n",
       "        0.59602141,  0.79195851,  0.71450581,  0.79574137,  0.76981737,\n",
       "        0.8286401 ,  0.56940083,  0.66838208,  0.70972941,  0.80970058,\n",
       "        0.79568826,  0.73653204,  0.7612948 ,  0.78197197,  0.80633683,\n",
       "        0.82762158,  0.76613696,  0.64604996,  0.75942131,  0.784965  ,\n",
       "        0.79434762,  0.72595702,  0.75313392,  0.70005725,  0.58885776,\n",
       "        0.78342709,  0.66885452,  0.74515733,  0.82843717,  0.73629993,\n",
       "        0.86466028,  0.82960087,  0.81927072,  0.74880753,  0.79008785,\n",
       "        0.85002998,  0.53137057,  0.78372646,  0.78252815,  1.87203881,\n",
       "        0.72267738,  0.81516837,  0.58137537,  0.82276502,  0.79116707,\n",
       "        0.79250033,  0.65292756,  0.76962384,  0.74345613,  0.76130141,\n",
       "        0.78127174,  0.84208815,  0.79337192,  0.79176294,  0.64591312,\n",
       "        0.74265219,  0.6192731 ,  0.75189286,  0.80810992,  0.71853192,\n",
       "        0.80414463,  0.83511747,  1.47152095,  0.76769846,  0.7662207 ,\n",
       "        0.68449268,  0.81266031,  0.73133535,  0.80676529,  0.77725926,\n",
       "        0.67524167,  0.7553412 ,  0.848774  ,  0.8062969 ,  0.75812513,\n",
       "        0.7125892 ,  0.78325279,  0.71131531,  0.76436808,  0.77290211,\n",
       "        0.71186696,  0.74379182,  0.36433435,  0.75595751,  0.84055957,\n",
       "        0.72216762,  0.72148582,  0.69555874,  0.81637454,  0.00911283,\n",
       "        0.71041631,  0.85198209,  0.88277441,  0.66742429,  0.82857214,\n",
       "        0.79820585,  0.77858895,  0.87867381,  0.68240631,  0.76847187,\n",
       "        0.85383658,  0.76174572,  0.83721506,  0.67375531,  0.75093046,\n",
       "        0.81956101,  0.82128519,  0.80027622,  0.7580007 ,  0.77132535,\n",
       "        0.72409234,  0.88309577,  0.62471155,  0.52747478,  0.8412101 ,\n",
       "        0.78605539,  0.79994958,  0.70374762,  0.80757913,  0.67659769,\n",
       "        0.80726505,  0.80920841,  0.81787475,  0.8389719 ,  0.69380688,\n",
       "        0.81413136,  0.57908016,  0.81102755,  0.69478389,  0.37357193,\n",
       "        0.76688391,  0.80414836,  0.77753052,  0.76265274,  0.62535629,\n",
       "        0.83270285,  0.78209877,  0.08994082,  0.77850067,  0.72980843,\n",
       "        0.84926655,  0.80759876,  0.8275778 ,  0.79979329,  0.75154231,\n",
       "        0.80541386,  0.81654321,  0.82983031,  0.74613645,  0.84759302,\n",
       "        0.77120512,  0.76633869,  0.80081515,  0.76683834,  0.74232787,\n",
       "        0.78827146,  0.60146226,  0.75130188,  0.83660818,  0.78245269,\n",
       "        0.79326858,  0.6735594 ,  0.81004425,  0.85381462,  0.76116108,\n",
       "        0.6158586 ,  0.81833751,  0.78396729,  0.76281021,  0.74401646,\n",
       "        0.82755205,  0.82260509,  0.82757943,  0.71804428,  0.79657059,\n",
       "        0.75766043,  0.60478385,  0.68822927,  0.7633545 ,  0.74427705,\n",
       "        0.70449499,  0.78743597,  0.8054026 ,  0.80860973,  0.81506758,\n",
       "        0.71994296,  0.83306314,  0.72368269,  0.75046391,  0.78400678])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression,Lasso,Ridge\n",
    "lrgn=LinearRegression()\n",
    "lrgn.fit(xx_train,yy_train)\n",
    "yy_pr_dlrg=lrgn.predict(xx_test)\n",
    "yy_pr_dlrg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "a9eadfb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.75357786,  0.81904682,  0.79921464,  0.81935759,  0.83230577,\n",
       "        0.679999  ,  0.67956461,  0.87503581,  0.74400425,  0.7549561 ,\n",
       "        0.65479272,  0.73613306,  0.79451923,  0.74228894,  0.79907313,\n",
       "        0.80411207,  0.81825318,  0.70541892,  0.74406159,  0.71904463,\n",
       "        0.77922715,  0.72325521,  0.86216797,  0.80725393,  0.69402783,\n",
       "        0.7078689 ,  1.00666224,  0.80099751,  0.71023945,  0.75197123,\n",
       "        0.781846  ,  0.84761358,  0.78642588,  0.75456124,  0.8122864 ,\n",
       "        0.52626376,  0.80225003,  0.75104675,  0.73999276,  0.75098221,\n",
       "        0.80303661,  0.74234842,  0.75181344,  0.73347001,  0.78860238,\n",
       "       -0.06116222,  0.72355673,  0.76493559,  0.81296475,  0.810197  ,\n",
       "        0.83082215,  0.70981764,  0.84267864,  0.8075573 ,  0.74152604,\n",
       "        0.75249026,  0.75681965,  0.81697872,  0.64603454,  0.75852816,\n",
       "        0.76774455,  0.72994044,  0.82186259,  0.79739426,  0.76905821,\n",
       "        0.79608734,  0.79907492,  0.80102198,  0.64447708,  0.77426506,\n",
       "        0.7530404 ,  0.78748242,  0.74313187,  0.80713843,  0.74700255,\n",
       "        0.71813553,  0.80369996,  0.74392844,  0.85535939,  0.81074481,\n",
       "        0.62274814,  0.83874679,  0.73588992,  0.77360628,  0.73548723,\n",
       "        0.73424768,  0.85216949,  0.83444159,  0.80250185,  0.83322568,\n",
       "        0.7298895 ,  0.80087773,  0.6662646 ,  0.81348447,  0.72362697,\n",
       "        0.83627686,  0.76111746,  0.74585207,  0.76727487,  0.80295956,\n",
       "        0.77195865,  0.7117796 ,  0.78883939,  0.80698901,  0.87749463,\n",
       "        0.80609417,  0.79863999,  0.70758751,  0.81935763,  0.6270334 ,\n",
       "        0.90317334,  0.74131597,  0.8816302 ,  0.73245315,  0.77570581,\n",
       "        0.71978795,  0.81515268,  0.78045823,  0.81781391,  0.73585845,\n",
       "        1.15294472,  0.70534008,  0.81386878,  0.79592966,  0.67477787,\n",
       "        0.80349121,  0.83563107,  0.84565016,  0.74131908,  0.6262018 ,\n",
       "        0.69728073,  0.76109528,  0.75920308,  0.08645407,  0.78264294,\n",
       "        0.80876123,  0.75770769,  0.73636722,  0.77934969,  0.82754948,\n",
       "        0.7770426 ,  0.84467602,  0.7938135 ,  0.48469528,  0.77928734,\n",
       "        0.71013636,  0.78547698,  0.81689597,  0.74798743,  0.83223066,\n",
       "        0.59703801,  0.79168271,  0.71802798,  0.79419555,  0.76935887,\n",
       "        0.83126146,  0.55900682,  0.66572673,  0.70955068,  0.81901975,\n",
       "        0.79289302,  0.73430805,  0.75971683,  0.78264633,  0.8054956 ,\n",
       "        0.82898242,  0.76442586,  0.65074764,  0.75775314,  0.78323645,\n",
       "        0.79222105,  0.72672223,  0.75128856,  0.6995483 ,  0.58902076,\n",
       "        0.78180103,  0.66819015,  0.74417749,  0.82813794,  0.73139306,\n",
       "        0.86161948,  0.82914865,  0.8199059 ,  0.74660428,  0.78803787,\n",
       "        0.85571713,  0.53007658,  0.78268811,  0.78325434,  1.63095098,\n",
       "        0.72209743,  0.81437921,  0.57893701,  0.8224561 ,  0.79153649,\n",
       "        0.78948974,  0.65181466,  0.76709924,  0.74241706,  0.76044737,\n",
       "        0.77917421,  0.84624265,  0.77219198,  0.79105733,  0.64596071,\n",
       "        0.74138686,  0.61995049,  0.75231146,  0.80642966,  0.71823892,\n",
       "        0.80531859,  0.84181566,  1.31577669,  0.76716749,  0.7645128 ,\n",
       "        0.68520266,  0.81230653,  0.72925879,  0.80509954,  0.77595051,\n",
       "        0.67307527,  0.7536722 ,  0.84794003,  0.80506355,  0.75711894,\n",
       "        0.71464376,  0.7821099 ,  0.7096851 ,  0.76365847,  0.772277  ,\n",
       "        0.71008104,  0.74171061,  0.37239764,  0.75541524,  0.83852995,\n",
       "        0.7213582 ,  0.72080043,  0.69531619,  0.81420689,  0.03704741,\n",
       "        0.71271419,  0.85176995,  0.88058985,  0.66848971,  0.82444427,\n",
       "        0.79677804,  0.77733379,  0.88896574,  0.68132225,  0.76738043,\n",
       "        0.84874912,  0.75960078,  0.83796375,  0.67459957,  0.75015001,\n",
       "        0.8198262 ,  0.81867012,  0.79832142,  0.75076156,  0.77014521,\n",
       "        0.72297578,  0.88017899,  0.62402213,  0.52863298,  0.83960134,\n",
       "        0.78488848,  0.79780193,  0.70206763,  0.80538973,  0.67539234,\n",
       "        0.80737894,  0.80765665,  0.81684829,  0.84008963,  0.69260798,\n",
       "        0.81258419,  0.59269696,  0.81046817,  0.69550401,  0.3745922 ,\n",
       "        0.76809876,  0.802553  ,  0.77493291,  0.76323944,  0.63070166,\n",
       "        0.83170674,  0.78174663,  0.39125588,  0.7773095 ,  0.72910085,\n",
       "        0.85604949,  0.80644678,  0.82537551,  0.80022914,  0.74980456,\n",
       "        0.79948337,  0.82014749,  0.82865731,  0.74618146,  0.84654411,\n",
       "        0.76856052,  0.76421521,  0.79932273,  0.76645374,  0.74134186,\n",
       "        0.78767499,  0.60030801,  0.74950284,  0.83444592,  0.77979215,\n",
       "        0.79308566,  0.67718502,  0.80730635,  0.85383705,  0.76625112,\n",
       "        0.6159635 ,  0.81703878,  0.78303731,  0.76199712,  0.74216158,\n",
       "        0.82542464,  0.82524713,  0.82646865,  0.71681523,  0.79583306,\n",
       "        0.7565981 ,  0.58948412,  0.68920575,  0.75972674,  0.74479071,\n",
       "        0.7039961 ,  0.78488309,  0.80451847,  0.81172131,  0.81434195,\n",
       "        0.71946658,  0.84786767,  0.72229063,  0.75015303,  0.78257056])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ridg_=Ridge(alpha=0.5)\n",
    "ridg_.fit(xx_train,yy_train)\n",
    "yy_pr_d_rgd_=ridg_.predict(xx_test)\n",
    "yy_pr_d_rgd=np.round(yy_pr_d_rgd_).astype(int)\n",
    "yy_pr_d_rgd_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "6baf3b5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7647058823529411\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score,confusion_matrix\n",
    "rgd_acc=accuracy_score(yy_pr_d_rgd,yy_test)\n",
    "print(rgd_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "747d9549",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lss_o=Lasso(alpha=0.5)\n",
    "lss_o.fit(xx_train,yy_train)\n",
    "yy_pr_d_lss_o=lss_o.predict(xx_test)\n",
    "yy_pr_d_lss_o=np.round(yy_pr_d_lss_o).astype(int)\n",
    "yy_pr_d_lss_o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "f97aba80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7529411764705882\n"
     ]
    }
   ],
   "source": [
    "lasso_acc=accuracy_score(yy_pr_d_lss_o,yy_test)\n",
    "print(lasso_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "df06eb49",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "8f51f90b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# using Ridge regularization\n",
    "logi_ridg_ = LogisticRegression(penalty='l2', C=1, solver='liblinear')\n",
    "logi_ridg_.fit(xx_train, yy_train)\n",
    "yy_pr_d_logi_ridg_ = logi_ridg_.predict(xx_test)\n",
    "\n",
    "\n",
    "# Lasso regularization\n",
    "logi_lss_o = LogisticRegression(penalty='l1', C=0.1, solver='liblinear')\n",
    "logi_lss_o.fit(xx_train, yy_train)\n",
    "yy_pr_d_logi_lss_o = logi_lss_o.predict(xx_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "ef70d98d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.07      0.13        84\n",
      "           1       0.77      0.99      0.86       256\n",
      "\n",
      "    accuracy                           0.76       340\n",
      "   macro avg       0.76      0.53      0.50       340\n",
      "weighted avg       0.76      0.76      0.68       340\n",
      "\n",
      "[[  6  78]\n",
      " [  2 254]]\n",
      "0.7647058823529411\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report,confusion_matrix,accuracy_score,ConfusionMatrixDisplay\n",
    "result=confusion_matrix(yy_test,yy_pr_d_logi_ridg_)\n",
    "print(classification_report(yy_test,yy_pr_d_logi_ridg_))\n",
    "print(result)\n",
    "score=accuracy_score(yy_test,yy_pr_d_logi_ridg_)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "2f2c24ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.05      0.09        84\n",
      "           1       0.76      1.00      0.86       256\n",
      "\n",
      "    accuracy                           0.76       340\n",
      "   macro avg       0.78      0.52      0.48       340\n",
      "weighted avg       0.77      0.76      0.67       340\n",
      "\n",
      "[[  4  80]\n",
      " [  1 255]]\n",
      "0.7617647058823529\n"
     ]
    }
   ],
   "source": [
    "result=confusion_matrix(yy_test,yy_pr_d_logi_lss_o)\n",
    "print(classification_report(yy_test,yy_pr_d_logi_lss_o))\n",
    "print(result)\n",
    "score=accuracy_score(yy_test,yy_pr_d_logi_lss_o)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "9b6c93aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.00549621,  0.03076301,  0.01888483, ...,  0.16326643,\n",
       "         0.10252078,  1.        ],\n",
       "       [-0.00549621,  0.03076301,  0.08871576, ...,  0.16326643,\n",
       "         0.10252078,  1.        ],\n",
       "       [-0.00704452,  0.02315909,  0.08871576, ...,  0.10571146,\n",
       "         0.10337778,  1.        ],\n",
       "       ...,\n",
       "       [-0.09967594,  0.06759499, -0.17002184, ..., -1.87633629,\n",
       "        -1.94099544,  0.        ],\n",
       "       [-0.08885333,  0.00782004, -0.12264524, ..., -2.02725355,\n",
       "        -2.05996147,  0.        ],\n",
       "       [-0.08473885, -0.02196062, -0.15929039, ..., -1.95231366,\n",
       "        -1.75897971,  0.        ]])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# using neural network\n",
    "XX=crds.iloc[:,:-1].values\n",
    "XX\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "fe9e8d0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['A1', 'A1', 'A1', ..., 'Caa1', 'Caa1', 'Caa1'], dtype=object)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "YY_R=crds.iloc[:,-1].values\n",
    "YY_R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "c5a9299e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  0,  0, ..., 15, 15, 15], dtype=int64)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "YY_R=lble.fit_transform(YY)\n",
    "YY_R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "cc5999e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([14,  0,  1,  3, 13, 13, 13,  3, 13,  3, 14, 13,  2, 11,  1, 13,  1,\n",
       "       13, 13, 12, 13,  0,  9,  0, 13, 11, 12, 14, 12,  7, 14,  4, 13, 14,\n",
       "        4, 12,  1, 10, 13, 10,  4, 13,  6, 13,  6, 13, 12, 12, 12,  0,  0,\n",
       "        6,  0,  3, 13, 14, 13, 14, 14, 14,  4, 12, 14,  1, 10, 12, 14,  4,\n",
       "       11, 10, 14, 11,  1,  0, 11, 14, 11, 13, 12,  3, 13,  0, 13, 13, 14,\n",
       "       13,  6,  0,  4,  0, 14,  4, 10, 14, 12,  1,  8, 13,  6,  9, 13, 10,\n",
       "       13,  4,  1,  4,  4, 13,  4, 10, 14,  6,  0, 13,  4, 12,  4, 10, 12,\n",
       "       14, 10, 15,  4,  6, 13,  6,  0,  3, 10, 11, 11,  0, 14,  9, 13,  1,\n",
       "       13, 12, 12,  1,  4, 11,  1, 10, 13,  1, 12,  4, 13, 10, 13, 14, 14,\n",
       "        6, 11,  2,  1, 14,  9, 10,  4, 13, 13,  4,  1,  1, 11, 10, 13, 13,\n",
       "        4, 11, 14, 13,  8, 13, 14, 13,  1, 13, 11,  0,  0, 12,  4,  3, 11,\n",
       "        3, 12,  2, 12,  0,  6,  0, 13,  4, 13, 13, 13,  1, 14,  2,  1,  1,\n",
       "       14, 14, 10, 10,  7, 13,  1,  6,  2,  3, 13, 10,  4, 14,  4, 13, 13,\n",
       "       13,  0, 14,  4,  1, 12, 12,  6, 14, 14,  6,  6, 14,  4,  4,  9, 13,\n",
       "       10, 11, 14,  1,  8, 14,  1,  1,  4,  3, 11, 14, 13, 14,  1,  4, 13,\n",
       "        4,  4, 14,  1,  4, 12, 12, 14, 13,  4, 12,  4, 10,  4, 11,  1,  3,\n",
       "        3,  4, 13,  3,  7,  4, 10, 11,  4,  6, 14,  1, 11,  6, 10,  8,  6,\n",
       "       10,  3,  1,  0,  1, 12,  7, 12,  4, 13,  4,  8, 13,  1, 12,  4,  6,\n",
       "       10,  4, 11, 13, 12, 14,  9,  0,  8, 13,  0,  0,  1, 13,  0, 12,  0,\n",
       "       13, 14, 12, 14,  6,  8,  7, 11, 12,  1,  4,  3, 13, 11, 13, 14, 11],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "XX_train,XX_test,YY_R_train,YY_R_test=train_test_split(XX,YY_R,test_size=0.20,random_state=42)\n",
    "XX_train\n",
    "XX_test\n",
    "YY_R_train\n",
    "YY_R_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "094858e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 3.52057498e-01,  8.60917820e-03,  3.55168546e-01, ...,\n",
       "        -3.67310957e-03,  8.39379060e-03,  5.64896152e-01],\n",
       "       [ 1.26311131e-01, -1.70415320e-01, -1.40072281e-01, ...,\n",
       "         6.01218820e-04,  1.06273887e-02,  5.64896152e-01],\n",
       "       [-1.77729233e-02, -1.75028218e-02, -4.92705671e-01, ...,\n",
       "        -4.75837768e-02, -2.82405847e-02,  5.64896152e-01],\n",
       "       ...,\n",
       "       [-3.11932499e-01, -2.42070508e-01, -7.34645462e-01, ...,\n",
       "        -5.19534147e-03,  1.23091729e-02, -1.77023688e+00],\n",
       "       [-2.18126878e+00,  7.53952356e-01, -7.08856482e-01, ...,\n",
       "         3.72409613e-03,  1.70926283e-02,  5.64896152e-01],\n",
       "       [-2.03649959e-01,  2.14737002e-02, -2.41789287e-02, ...,\n",
       "        -1.83765991e-03,  2.45638704e-02,  5.64896152e-01]])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scal_r=StandardScaler()\n",
    "scal_r.fit(XX_train)\n",
    "XX_train=scal_r.transform(XX_train)\n",
    "XX_test=scal_r.transform(XX_test)\n",
    "XX_test\n",
    "XX_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "6635c7f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classifi report for Investment:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        84\n",
      "           1       1.00      0.09      0.17       256\n",
      "           2       0.00      0.00      0.00         0\n",
      "           3       0.00      0.00      0.00         0\n",
      "           4       0.00      0.00      0.00         0\n",
      "           6       0.00      0.00      0.00         0\n",
      "           7       0.00      0.00      0.00         0\n",
      "           8       0.00      0.00      0.00         0\n",
      "           9       0.00      0.00      0.00         0\n",
      "          10       0.00      0.00      0.00         0\n",
      "          11       0.00      0.00      0.00         0\n",
      "          12       0.00      0.00      0.00         0\n",
      "          13       0.00      0.00      0.00         0\n",
      "          14       0.00      0.00      0.00         0\n",
      "          15       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.07       340\n",
      "   macro avg       0.07      0.01      0.01       340\n",
      "weighted avg       0.75      0.07      0.13       340\n",
      "\n",
      "Confusion Matrix for Investment: [[ 0  0  0  0  0 12  7  5  3 31 21  0  2  1  2]\n",
      " [13 24  2  9 56  0  1  0  0  3  0 27 68 53  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]]\n",
      "Classification Report for Rating:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.46      0.25      0.32        24\n",
      "           1       0.33      0.24      0.28        33\n",
      "           2       0.50      0.20      0.29         5\n",
      "           3       0.33      0.20      0.25        15\n",
      "           4       0.54      0.71      0.61        42\n",
      "           6       0.58      0.37      0.45        19\n",
      "           7       0.25      0.40      0.31         5\n",
      "           8       0.40      0.29      0.33         7\n",
      "           9       1.00      0.50      0.67         6\n",
      "          10       0.53      0.78      0.63        23\n",
      "          11       0.43      0.39      0.41        23\n",
      "          12       0.41      0.35      0.38        31\n",
      "          13       0.51      0.57      0.54        63\n",
      "          14       0.52      0.65      0.58        43\n",
      "          15       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.48       340\n",
      "   macro avg       0.45      0.39      0.40       340\n",
      "weighted avg       0.48      0.48      0.47       340\n",
      "\n",
      "Confusion Matrix for Rating: [[ 6  1  0  0  5  0  0  0  0  0  0  6  3  3  0]\n",
      " [ 3  8  1  2  4  0  1  0  0  0  0  1  7  6  0]\n",
      " [ 0  0  1  0  0  0  0  0  0  1  0  1  2  0  0]\n",
      " [ 0  0  0  3  3  0  0  0  0  2  0  1  5  1  0]\n",
      " [ 1  2  0  0 30  0  0  0  0  0  0  2  3  4  0]\n",
      " [ 0  0  0  0  0  7  1  1  0  3  5  0  0  1  1]\n",
      " [ 0  0  0  0  0  0  2  1  0  1  1  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  2  0  2  1  0  2  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  3  2  1  0  0  0  0]\n",
      " [ 0  0  0  0  0  1  0  0  0 18  4  0  0  0  0]\n",
      " [ 0  0  0  0  0  4  4  1  0  4  9  0  0  0  1]\n",
      " [ 0  4  0  2  9  0  0  0  0  0  0 11  4  1  0]\n",
      " [ 3  5  0  2  4  0  0  0  0  0  0  3 36 10  0]\n",
      " [ 0  4  0  0  1  0  0  0  0  0  0  2  8 28  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  1  0  0  0  0  0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(50,), max_iter=1000, random_state=42)\n",
    "\n",
    "mlp.fit(XX_train, YY_train)\n",
    "# Predicting is it a firm is investment grade or not\n",
    "y_ig_pred = mlp.predict(XX_test)\n",
    "print('classifi report for Investment:',classification_report(yy_test, y_ig_pred))\n",
    "print('Confusion Matrix for Investment:',confusion_matrix(yy_test, y_ig_pred))\n",
    "\n",
    "# Prediction of rating of the firms\n",
    "y_rating_pred = mlp.predict(XX_test)\n",
    "print('Classification Report for Rating:',classification_report(YY_test, y_rating_pred))\n",
    "print('Confusion Matrix for Rating:',confusion_matrix(YY_test, y_rating_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "f5b27a45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4823529411764706\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "mlp.fit(XX_train,YY_R_train)\n",
    "y_predmlp=mlp.predict(XX_test)\n",
    "mlpacc=accuracy_score(y_predmlp,YY_R_test)\n",
    "print(mlpacc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "58e527cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.46      0.25      0.32        24\n",
      "           1       0.33      0.24      0.28        33\n",
      "           2       0.50      0.20      0.29         5\n",
      "           3       0.33      0.20      0.25        15\n",
      "           4       0.54      0.71      0.61        42\n",
      "           6       0.58      0.37      0.45        19\n",
      "           7       0.25      0.40      0.31         5\n",
      "           8       0.40      0.29      0.33         7\n",
      "           9       1.00      0.50      0.67         6\n",
      "          10       0.53      0.78      0.63        23\n",
      "          11       0.43      0.39      0.41        23\n",
      "          12       0.41      0.35      0.38        31\n",
      "          13       0.51      0.57      0.54        63\n",
      "          14       0.52      0.65      0.58        43\n",
      "          15       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.48       340\n",
      "   macro avg       0.45      0.39      0.40       340\n",
      "weighted avg       0.48      0.48      0.47       340\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(YY_R_test,y_predmlp))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f0bb2b7",
   "metadata": {},
   "source": [
    "mlp.fit(xx_train,yy_train)\n",
    "y_predmlp=mlp.predict(xx_test)\n",
    "mlpacc=accuracy_score(y_predmlp,yy_test)\n",
    "print(mlpacc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "8499a34e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.93      0.94        84\n",
      "           1       0.98      0.98      0.98       256\n",
      "\n",
      "    accuracy                           0.97       340\n",
      "   macro avg       0.96      0.96      0.96       340\n",
      "weighted avg       0.97      0.97      0.97       340\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(yy_test,y_predmlp))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca5ff88b",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb7f2f98",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
